{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This document provides an overview of operating the code pipeline and functions documentation. This repo provides code for 3d analysis. In case of need of any editional (technical) information reach out to the development team: Martin Vagenknecht (martin.vagenknecht@merck.com) Petr Hrobar (petr.hrobar@merck.com) Jindrich Soukup (jindrich.soukup@merck.com)","title":"Home"},{"location":"#this-document-provides-an-overview-of-operating-the-code-pipeline-and-functions-documentation","text":"This repo provides code for 3d analysis. In case of need of any editional (technical) information reach out to the development team: Martin Vagenknecht (martin.vagenknecht@merck.com) Petr Hrobar (petr.hrobar@merck.com) Jindrich Soukup (jindrich.soukup@merck.com)","title":"This document provides an overview of operating the code pipeline and functions documentation."},{"location":"Segmentation%20Quality/","text":"Supported segmentation methods are random forest , UNET and thresholding In the detailed analysis, Machine Learning based models seems to be providing the best results. 1) Comparision of segmentation methods 2) Unet Segmentation quality (3D view) 2) Corrective Characteristic of ML models Segmentation Machine Learning models allow for certain level of flexibility in the GroundTruth Data.","title":"Segmentation Quality"},{"location":"Segmentation%20Quality/#1-comparision-of-segmentation-methods","text":"","title":"1) Comparision of segmentation methods"},{"location":"Segmentation%20Quality/#2-unet-segmentation-quality-3d-view","text":"","title":"2) Unet Segmentation quality (3D view)"},{"location":"Segmentation%20Quality/#2-corrective-characteristic-of-ml-models","text":"Segmentation Machine Learning models allow for certain level of flexibility in the GroundTruth Data.","title":"2) Corrective Characteristic of ML models"},{"location":"code%20usuage/","text":"Code Usage The code can be operated in 2 separated ways: 1) Fully automated pipeline 2) Manual Usage of Modules 1)Fully automated pipeline which analyzis entire study automaticaly and loggs the results (final profiles) into mlflow. (All middle steps e.g. segmented masks are dumped in the disk). This approach requires the usage of config.json file, which contains details regarding the pipeline settings (see config page) . Once the config.json is prepared, the code can be used via 2 files: main.py master_script.py main.py this file used for the CommandLine (terminal) interface. This file shall be used when the entire analysis should be performed automaticaly and one in intested only in inspecting the results in mlflow . Using a command line interface (terminal), the code can be run as: main module: module to run the whole pipleline main ( config_path ) Main Function for the entire pipeline for automated usage. It wraps entire pipeline into one function which can be source from the terminal. Entire process is fully automated and uses config.json file. See Config file documentation Parameters config_path : (pathlib.PosixPath) Relative path to the config file defining the entire process (Notice the expected folder structure). ppdm \u2514\u2500 data \u2514\u2500 5IT_STUDY \u2514\u2500 **config.json** \u2514\u2500 source \u2514\u2500raw \u2514\u2500tumor \u2502 \u2514\u2500 5IT-4X_Ch2_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch2_z1300.tiff \u251c\u2500vessel \u2502 \u2514\u2500 5IT-4X_Ch3_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch3_z1300.tiff \u2502\u2500virus \u2514\u2500 5IT-4X_Ch1_z0300.tiff \u2514\u2500 ... \u2514\u25005IT-4X_Ch1_z1300.tiff Returns Results are dumbed on the disk (segmented masks, distance transform) and save to mlflow (if provided in config). Example Usuage >>> conda activate 3 d >>> python main . py -- Config File : data / 5 IT_DUMMY_STUDY / config . json Source code in ppdm/main.py def main ( config_path : pathlib . PosixPath ) -> None : \"\"\" Main Function for the entire pipeline for automated usage. It wraps entire pipeline into one function which can be source from the terminal. Entire process is fully automated and uses **config.json** file. See [Config file documentation](config.md) Parameters ---------- **config_path** : *(pathlib.PosixPath)* Relative path to the config file defining the entire process (Notice the expected folder structure). ```bash ppdm \u2514\u2500 data \u2514\u2500 5IT_STUDY \u2514\u2500 **config.json** \u2514\u2500 source \u2514\u2500raw \u2514\u2500tumor \u2502 \u2514\u2500 5IT-4X_Ch2_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch2_z1300.tiff \u251c\u2500vessel \u2502 \u2514\u2500 5IT-4X_Ch3_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch3_z1300.tiff \u2502\u2500virus \u2514\u2500 5IT-4X_Ch1_z0300.tiff \u2514\u2500 ... \u2514\u25005IT-4X_Ch1_z1300.tiff ``` Returns ------ Results are dumbed on the disk (segmented masks, distance transform) and save to mlflow (if provided in config). Example Usuage -------------- ```python >>>conda activate 3d >>>python main.py --Config File: data/5IT_DUMMY_STUDY/config.json ``` \"\"\" # Config file config_path = root_directory_path . joinpath ( config_path ) experiment = load_config ( config_path ) # script name to log in MLFLOW SCRIPT_NAME = \"main.py\" ####################################### # # DATA PREPROCESSING # ##################################### experiment [ \"data\" ][ \"source\" ][ \"transformed\" ] = data_preprocessing_wrapper ( experiment [ \"data\" ][ \"source\" ][ \"raw\" ] ) ####################################### # # SEGMENTATION # ##################################### # segmentation of blood vessels out_path = segmentation_wrapper ( experiment [ \"data\" ][ \"source\" ][ \"transformed\" ][ \"vessel\" ], ** experiment [ \"segmentation_method_vessel\" ], ) experiment [ \"data\" ][ \"results\" ][ \"segmentation\" ][ \"vessel\" ] = out_path # segmentation of tumors out_path = segmentation_wrapper ( experiment [ \"data\" ][ \"source\" ][ \"transformed\" ][ \"tumor\" ], ** experiment [ \"segmentation_method_tumor\" ], ) experiment [ \"data\" ][ \"results\" ][ \"segmentation\" ][ \"tumor\" ] = out_path # # postprocessing tumor masks out_path = postprocess_masks ( experiment [ \"data\" ][ \"results\" ][ \"segmentation\" ][ \"tumor\" ], ** experiment [ \"segmentation_postprocessing_tumor\" ], ) experiment [ \"data\" ][ \"results\" ][ \"segmentation_postprocessing\" ][ \"tumor\" ] = out_path ####################################### # # DISTANCE TRANSFORM # ##################################### out_path = calculate_distance_tranform ( experiment [ \"data\" ][ \"results\" ][ \"segmentation\" ][ \"vessel\" ], ** experiment [ \"distance_tranform\" ][ \"method_parameters\" ], ) experiment [ \"data\" ][ \"results\" ][ \"distance_transform\" ][ \"vessel\" ] = out_path ####################################### # # PROFILE # ##################################### # calculating the final profile profiles = calculate_profile ( experiment [ \"data\" ][ \"source\" ][ \"transformed\" ][ \"virus\" ], experiment [ \"data\" ][ \"results\" ][ \"distance_transform\" ][ \"vessel\" ], experiment [ \"data\" ][ \"results\" ][ \"segmentation_postprocessing\" ][ \"tumor\" ], experiment [ \"pixels_to_microns\" ], force_overwrite = False , ) ####################################### # # ML-FLOW LOGGING # ##################################### print ( MLFLOW_EXPERIMENT_NAME ) if experiment [ \"mlflow_logging\" ]: mlflow_logging ( experiment , profiles , MLFLOW_TRACKING_URI , MLFLOW_EXPERIMENT_NAME , experiment [ \"mlflow_run_name\" ], SCRIPT_NAME , ) master_script.py This file is a script version of main.py file. This means that it allows for interactive (cell-by-cell) usage. 2)Manual Usage of Modules As the entire code is written as a package, one can acces individual modules (functions) and use them wholly separatelly for own purposes e.g. only for blood vessels segmentations/distance transform. This approach does not require the config.json file. See the Documentation of individual modules for further details: Preprocessing, Segmentation, Postprocessing, Distance Transform, Profiles. Even when using Modules individualy, the function's documentation can still be accesed within the jupyterlab. When using Contextual Helper we see the functions documentation (see below).","title":"Code usuage"},{"location":"code%20usuage/#code-usage","text":"The code can be operated in 2 separated ways: 1) Fully automated pipeline 2) Manual Usage of Modules 1)Fully automated pipeline which analyzis entire study automaticaly and loggs the results (final profiles) into mlflow. (All middle steps e.g. segmented masks are dumped in the disk). This approach requires the usage of config.json file, which contains details regarding the pipeline settings (see config page) . Once the config.json is prepared, the code can be used via 2 files: main.py master_script.py","title":"Code Usage"},{"location":"code%20usuage/#mainpy","text":"this file used for the CommandLine (terminal) interface. This file shall be used when the entire analysis should be performed automaticaly and one in intested only in inspecting the results in mlflow . Using a command line interface (terminal), the code can be run as: main module: module to run the whole pipleline","title":"main.py"},{"location":"code%20usuage/#main.main","text":"Main Function for the entire pipeline for automated usage. It wraps entire pipeline into one function which can be source from the terminal. Entire process is fully automated and uses config.json file. See Config file documentation","title":"main()"},{"location":"code%20usuage/#main.main--parameters","text":"config_path : (pathlib.PosixPath) Relative path to the config file defining the entire process (Notice the expected folder structure). ppdm \u2514\u2500 data \u2514\u2500 5IT_STUDY \u2514\u2500 **config.json** \u2514\u2500 source \u2514\u2500raw \u2514\u2500tumor \u2502 \u2514\u2500 5IT-4X_Ch2_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch2_z1300.tiff \u251c\u2500vessel \u2502 \u2514\u2500 5IT-4X_Ch3_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch3_z1300.tiff \u2502\u2500virus \u2514\u2500 5IT-4X_Ch1_z0300.tiff \u2514\u2500 ... \u2514\u25005IT-4X_Ch1_z1300.tiff","title":"Parameters"},{"location":"code%20usuage/#main.main--returns","text":"Results are dumbed on the disk (segmented masks, distance transform) and save to mlflow (if provided in config).","title":"Returns"},{"location":"code%20usuage/#main.main--example-usuage","text":">>> conda activate 3 d >>> python main . py -- Config File : data / 5 IT_DUMMY_STUDY / config . json Source code in ppdm/main.py def main ( config_path : pathlib . PosixPath ) -> None : \"\"\" Main Function for the entire pipeline for automated usage. It wraps entire pipeline into one function which can be source from the terminal. Entire process is fully automated and uses **config.json** file. See [Config file documentation](config.md) Parameters ---------- **config_path** : *(pathlib.PosixPath)* Relative path to the config file defining the entire process (Notice the expected folder structure). ```bash ppdm \u2514\u2500 data \u2514\u2500 5IT_STUDY \u2514\u2500 **config.json** \u2514\u2500 source \u2514\u2500raw \u2514\u2500tumor \u2502 \u2514\u2500 5IT-4X_Ch2_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch2_z1300.tiff \u251c\u2500vessel \u2502 \u2514\u2500 5IT-4X_Ch3_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch3_z1300.tiff \u2502\u2500virus \u2514\u2500 5IT-4X_Ch1_z0300.tiff \u2514\u2500 ... \u2514\u25005IT-4X_Ch1_z1300.tiff ``` Returns ------ Results are dumbed on the disk (segmented masks, distance transform) and save to mlflow (if provided in config). Example Usuage -------------- ```python >>>conda activate 3d >>>python main.py --Config File: data/5IT_DUMMY_STUDY/config.json ``` \"\"\" # Config file config_path = root_directory_path . joinpath ( config_path ) experiment = load_config ( config_path ) # script name to log in MLFLOW SCRIPT_NAME = \"main.py\" ####################################### # # DATA PREPROCESSING # ##################################### experiment [ \"data\" ][ \"source\" ][ \"transformed\" ] = data_preprocessing_wrapper ( experiment [ \"data\" ][ \"source\" ][ \"raw\" ] ) ####################################### # # SEGMENTATION # ##################################### # segmentation of blood vessels out_path = segmentation_wrapper ( experiment [ \"data\" ][ \"source\" ][ \"transformed\" ][ \"vessel\" ], ** experiment [ \"segmentation_method_vessel\" ], ) experiment [ \"data\" ][ \"results\" ][ \"segmentation\" ][ \"vessel\" ] = out_path # segmentation of tumors out_path = segmentation_wrapper ( experiment [ \"data\" ][ \"source\" ][ \"transformed\" ][ \"tumor\" ], ** experiment [ \"segmentation_method_tumor\" ], ) experiment [ \"data\" ][ \"results\" ][ \"segmentation\" ][ \"tumor\" ] = out_path # # postprocessing tumor masks out_path = postprocess_masks ( experiment [ \"data\" ][ \"results\" ][ \"segmentation\" ][ \"tumor\" ], ** experiment [ \"segmentation_postprocessing_tumor\" ], ) experiment [ \"data\" ][ \"results\" ][ \"segmentation_postprocessing\" ][ \"tumor\" ] = out_path ####################################### # # DISTANCE TRANSFORM # ##################################### out_path = calculate_distance_tranform ( experiment [ \"data\" ][ \"results\" ][ \"segmentation\" ][ \"vessel\" ], ** experiment [ \"distance_tranform\" ][ \"method_parameters\" ], ) experiment [ \"data\" ][ \"results\" ][ \"distance_transform\" ][ \"vessel\" ] = out_path ####################################### # # PROFILE # ##################################### # calculating the final profile profiles = calculate_profile ( experiment [ \"data\" ][ \"source\" ][ \"transformed\" ][ \"virus\" ], experiment [ \"data\" ][ \"results\" ][ \"distance_transform\" ][ \"vessel\" ], experiment [ \"data\" ][ \"results\" ][ \"segmentation_postprocessing\" ][ \"tumor\" ], experiment [ \"pixels_to_microns\" ], force_overwrite = False , ) ####################################### # # ML-FLOW LOGGING # ##################################### print ( MLFLOW_EXPERIMENT_NAME ) if experiment [ \"mlflow_logging\" ]: mlflow_logging ( experiment , profiles , MLFLOW_TRACKING_URI , MLFLOW_EXPERIMENT_NAME , experiment [ \"mlflow_run_name\" ], SCRIPT_NAME , )","title":"Example Usuage"},{"location":"code%20usuage/#master_scriptpy","text":"This file is a script version of main.py file. This means that it allows for interactive (cell-by-cell) usage. 2)Manual Usage of Modules As the entire code is written as a package, one can acces individual modules (functions) and use them wholly separatelly for own purposes e.g. only for blood vessels segmentations/distance transform. This approach does not require the config.json file. See the Documentation of individual modules for further details: Preprocessing, Segmentation, Postprocessing, Distance Transform, Profiles. Even when using Modules individualy, the function's documentation can still be accesed within the jupyterlab. When using Contextual Helper we see the functions documentation (see below).","title":"master_script.py"},{"location":"code_overview/","text":"Code Pipeline overview This document provides an overview of operating the code pipeline and the expected input of the data for the analysis. ```","title":"Code Pipeline overview"},{"location":"code_overview/#code-pipeline-overview","text":"","title":"Code Pipeline overview"},{"location":"code_overview/#this-document-provides-an-overview-of-operating-the-code-pipeline-and-the-expected-input-of-the-data-for-the-analysis","text":"```","title":"This document provides an overview of operating the code pipeline and the expected input of the data for the analysis."},{"location":"config/","text":"Config file contains an entire setting for the automated analysis via main.py file and master_script.py . It allows changing methods for blood vessels segmentation as well as changing pre-trained models to use. config.json file All Changeble parameters are listed bellow: Main Key method/value method_parameters segmentation_method_tumor thresholding method : [th_triangle,th_yen,th_otsu] segmentation_method_vessel random_forest model_file : relative path unet model_file : relative path thresholding method : [th_triangle,th_yen,th_otsu] segmentation_postprocessing_tumor split_tumor_into_core_and_periphery periphery_as_ratio_of_max_distance :<0; 1> distance_tranform stack_size : int pixels_to_microns float mlflow_logging bool mlflow_run_name str Example of possible config.json file. { \"segmentation_method_tumor\" : { \"method\" : \"thresholding\" , # Select segmentation method for tumor channel (here \"thresholding\") \"method_parameters\" : { \"method\" : \"th_triangle\" # What thresholding method to use: yen, triangle, otsu... } } , \"segmentation_method_vessel\" : { \"method\" : \"unet\" , # What method to use for blood vessels segmentation \"method_parameters\" : { \"model_file\" : \"ppdm/data/unet_model.pt\" , # path to the pre-trained model } } , \"segmentation_postprocessing_tumor\" : { # Tumor postprocesing - splitting the brains to core and periphery \"method\" : \"split_tumor_into_core_and_periphery\" , # Split tumor to the core and periphery \"method_parameters\" : {} # No parameter necessary for this method - defaults to 0.2 (20 percent core, 80 periphery) } , \"distance_tranform\" : { # (Outer) Distance Transform for the blood vessels distance \"method_parameters\" : { # How many layers stacked together inside DT aggregation \"stack_size\" : 100 } } \"pixels_to_microns\" : 4 , # Multiplication constant for converting pixels to micrones \"mlflow_logging\" : true # Bool parameters if the results should be saved to mlflow. \"mlflow_run_name\" : \"DEMO\" # Name of the experiment which should be used for the logging }","title":"Config"},{"location":"config/#configjson-file","text":"All Changeble parameters are listed bellow: Main Key method/value method_parameters segmentation_method_tumor thresholding method : [th_triangle,th_yen,th_otsu] segmentation_method_vessel random_forest model_file : relative path unet model_file : relative path thresholding method : [th_triangle,th_yen,th_otsu] segmentation_postprocessing_tumor split_tumor_into_core_and_periphery periphery_as_ratio_of_max_distance :<0; 1> distance_tranform stack_size : int pixels_to_microns float mlflow_logging bool mlflow_run_name str","title":"config.json file"},{"location":"config/#example-of-possible-configjson-file","text":"{ \"segmentation_method_tumor\" : { \"method\" : \"thresholding\" , # Select segmentation method for tumor channel (here \"thresholding\") \"method_parameters\" : { \"method\" : \"th_triangle\" # What thresholding method to use: yen, triangle, otsu... } } , \"segmentation_method_vessel\" : { \"method\" : \"unet\" , # What method to use for blood vessels segmentation \"method_parameters\" : { \"model_file\" : \"ppdm/data/unet_model.pt\" , # path to the pre-trained model } } , \"segmentation_postprocessing_tumor\" : { # Tumor postprocesing - splitting the brains to core and periphery \"method\" : \"split_tumor_into_core_and_periphery\" , # Split tumor to the core and periphery \"method_parameters\" : {} # No parameter necessary for this method - defaults to 0.2 (20 percent core, 80 periphery) } , \"distance_tranform\" : { # (Outer) Distance Transform for the blood vessels distance \"method_parameters\" : { # How many layers stacked together inside DT aggregation \"stack_size\" : 100 } } \"pixels_to_microns\" : 4 , # Multiplication constant for converting pixels to micrones \"mlflow_logging\" : true # Bool parameters if the results should be saved to mlflow. \"mlflow_run_name\" : \"DEMO\" # Name of the experiment which should be used for the logging }","title":"Example of possible config.json file."},{"location":"methodology_overview/","text":"The entire process is described in the following Diagram. Blood vessels segmentation Blood vessels and segmented in order to obtain binary masks. Code implementation can be found in ( segmentation.py ) see segmentation module documentation and examples . Tumors segmentation Tumor are segmented and may be post-processed (e.g. splitted to core and periphery brain regions). Code implementation can be found in ( segmentation.py ) see segmentation module documentation and examples . Distance Map Once the blood vessels are segmented, an outer distance transform is performed to calculate the distance from blood vessel. This step is implemented in ( distance_transform.py ) script. Documentation and examples of distance transfrom module . Data Collection And Aggregation Once the distance transform of blood vessels is calculated and tumor are segmented into masks. The final profile is calculated. see profiles module documentation and examples .","title":"Methodology overview"},{"location":"methodology_overview/#blood-vessels-segmentation","text":"Blood vessels and segmented in order to obtain binary masks. Code implementation can be found in ( segmentation.py ) see segmentation module documentation and examples .","title":"Blood vessels segmentation"},{"location":"methodology_overview/#tumors-segmentation","text":"Tumor are segmented and may be post-processed (e.g. splitted to core and periphery brain regions). Code implementation can be found in ( segmentation.py ) see segmentation module documentation and examples .","title":"Tumors segmentation"},{"location":"methodology_overview/#distance-map","text":"Once the blood vessels are segmented, an outer distance transform is performed to calculate the distance from blood vessel. This step is implemented in ( distance_transform.py ) script. Documentation and examples of distance transfrom module .","title":"Distance Map"},{"location":"methodology_overview/#data-collection-and-aggregation","text":"Once the distance transform of blood vessels is calculated and tumor are segmented into masks. The final profile is calculated. see profiles module documentation and examples .","title":"Data Collection And Aggregation"},{"location":"prerequisites/","text":"PREREQUISITES The code expects to have : Python installed on HPC (e.g. via minoconda) Python virtual environment containing all required packages and modules (3d environment) In order to install infrastructure on the hpc server (python, packages, etc.) follow this guide . Folder Structure Due to the size of the data, every single step dumps the results on the disk (as a substitute for the RAM). Therefore, the code operates with a fixed folder structure When analyzing one particular study ( 5_IT_STUDY in this case), the following folders structure of three channels (vessels, tumors, virus) including the config.json file is expected. Expected Folder Structure The root directory is considered the ppdm folder (see tree diagram below) ppdm \u2514\u2500 data \u2514\u2500 5IT_STUDY \u2514\u2500 config.json \u2514\u2500 source \u2514\u2500raw \u2514\u2500tumor \u2502 \u2514\u2500 5IT-4X_Ch2_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch2_z1300.tiff \u251c\u2500vessel \u2502 \u2514\u2500 5IT-4X_Ch3_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch3_z1300.tiff \u2502\u2500virus \u2514\u2500 5IT-4X_Ch1_z0300.tiff \u2514\u2500 ... \u2514\u25005IT-4X_Ch1_z1300.tiff .tiff files are expected to be exported by Imaris software. We expect that all the three channels have the same format (one channel tiff file) of the same size. NOTE : This folder structure is expected only for the Fully automated pipeline usuage. However, we recommend uttilizing this structure even when using the code in a Manual Usage of Modules .","title":"Prerequisites"},{"location":"prerequisites/#prerequisites","text":"The code expects to have : Python installed on HPC (e.g. via minoconda) Python virtual environment containing all required packages and modules (3d environment) In order to install infrastructure on the hpc server (python, packages, etc.) follow this guide .","title":"PREREQUISITES"},{"location":"prerequisites/#folder-structure","text":"Due to the size of the data, every single step dumps the results on the disk (as a substitute for the RAM). Therefore, the code operates with a fixed folder structure When analyzing one particular study ( 5_IT_STUDY in this case), the following folders structure of three channels (vessels, tumors, virus) including the config.json file is expected. Expected Folder Structure The root directory is considered the ppdm folder (see tree diagram below) ppdm \u2514\u2500 data \u2514\u2500 5IT_STUDY \u2514\u2500 config.json \u2514\u2500 source \u2514\u2500raw \u2514\u2500tumor \u2502 \u2514\u2500 5IT-4X_Ch2_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch2_z1300.tiff \u251c\u2500vessel \u2502 \u2514\u2500 5IT-4X_Ch3_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch3_z1300.tiff \u2502\u2500virus \u2514\u2500 5IT-4X_Ch1_z0300.tiff \u2514\u2500 ... \u2514\u25005IT-4X_Ch1_z1300.tiff .tiff files are expected to be exported by Imaris software. We expect that all the three channels have the same format (one channel tiff file) of the same size. NOTE : This folder structure is expected only for the Fully automated pipeline usuage. However, we recommend uttilizing this structure even when using the code in a Manual Usage of Modules .","title":"Folder Structure"},{"location":"Modules/distance_transform/","text":"Distance Transform distance transform module: module for computing distance transform on segmented masks This module consists of four main functions: calculate_distance_tranform calculate_distance_tranform ( data_path , stack_size = 100 ) Wrapper function that calculates the distance transform on the segmented blood vessels masks. Due to the size of the data it calculated the distance transform using overlapping cubes. Parameters data_path : (pathlib.PosixPath) relative path for the segmented masks to be used for the distance transform stack_size : (int) TODO: DESCTIBE PROPERLY Returns output_directory : *(pathlib.PosixPath) outputs relative path for the folders with calculated distance transform. Results are dumbed on the disk. Example Usuage >>> from src.distance_tranform import calculate_distance_tranform >>> segmented_vessels_path = Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/segmentation/vessel/segment___unet___model_file-model' ) >>> calculate_distance_tranform ( study_paths ) >>> output : Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/distance_transform/vessel/distance_tranform___segment___unet___model_file-model' ) Source code in src/distance_transform.py @log_step def calculate_distance_tranform ( data_path : pathlib . PosixPath , stack_size : int = 100 ) -> pathlib . PosixPath : \"\"\" Wrapper function that calculates the distance transform on the segmented blood vessels masks. Due to the size of the data it calculated the distance transform using overlapping cubes. Parameters ---------- **data_path**: *(pathlib.PosixPath)* relative path for the segmented masks to be used for the distance transform **stack_size**: *(int)* TODO: DESCTIBE PROPERLY Returns ------ **output_directory**: *(pathlib.PosixPath) outputs relative path for the folders with calculated distance transform. Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.distance_tranform import calculate_distance_tranform >>>segmented_vessels_path = Path('ppdm/data/5IT_DUMMY_STUDY/results/segmentation/vessel/segment___unet___model_file-model') >>>calculate_distance_tranform(study_paths) >>>output: Path('ppdm/data/5IT_DUMMY_STUDY/results/distance_transform/vessel/distance_tranform___segment___unet___model_file-model') ``` \"\"\" module_results_path = \"results/distance_transform\" module_name = \"distance_tranform\" output_folder_name = join_to_string ([ module_name , data_path . stem ]) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) directory_ok = check_content_of_two_directories ( data_path , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) # step1 - create overlapping bricks submodule_name = \"tmp_overlapping_bricks\" output_folder_name = join_to_string ([ submodule_name , data_path . stem ]) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) if output_directory . exists (): remove_content ( output_directory ) overlapping_bricks = _merge_with_overlap ( data_path , output_directory , stack_size = stack_size ) # step2 - calculate distance transform on overlapping brikcs submodule_name = \"tmp_dt_overlapping_bricks\" output_folder_name = join_to_string ([ submodule_name , data_path . stem ]) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) if output_directory . exists (): remove_content ( output_directory ) overlapping_bricks_dt = _compute_distance_transform ( overlapping_bricks , output_directory ) # step3 - aggregate information from overlapping bricks submodule_name = \"tmp_dt_aggregated_bricks\" output_folder_name = join_to_string ([ submodule_name , data_path . stem ]) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) if output_directory . exists (): remove_content ( output_directory ) aggregated_bricks_dt = _aggregate ( overlapping_bricks_dt , output_directory ) # final step4 - slice bricks back into individual layers output_folder_name = join_to_string ([ module_name , data_path . stem ]) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) if output_directory . exists (): remove_content ( output_directory ) names_of_individual_layers = data_path _split ( aggregated_bricks_dt , output_directory , names_of_individual_layers ) return output_directory","title":"Distance Transform"},{"location":"Modules/distance_transform/#distance-transform","text":"","title":"Distance Transform"},{"location":"Modules/distance_transform/#src.distance_transform--distance-transform-module","text":"","title":"distance transform module:"},{"location":"Modules/distance_transform/#src.distance_transform--module-for-computing-distance-transform-on-segmented-masks","text":"","title":"module for computing distance transform on segmented masks"},{"location":"Modules/distance_transform/#src.distance_transform--this-module-consists-of-four-main-functions","text":"calculate_distance_tranform","title":"This module consists of four main functions:"},{"location":"Modules/distance_transform/#src.distance_transform.calculate_distance_tranform","text":"Wrapper function that calculates the distance transform on the segmented blood vessels masks. Due to the size of the data it calculated the distance transform using overlapping cubes.","title":"calculate_distance_tranform()"},{"location":"Modules/distance_transform/#src.distance_transform.calculate_distance_tranform--parameters","text":"data_path : (pathlib.PosixPath) relative path for the segmented masks to be used for the distance transform stack_size : (int) TODO: DESCTIBE PROPERLY","title":"Parameters"},{"location":"Modules/distance_transform/#src.distance_transform.calculate_distance_tranform--returns","text":"output_directory : *(pathlib.PosixPath) outputs relative path for the folders with calculated distance transform. Results are dumbed on the disk.","title":"Returns"},{"location":"Modules/distance_transform/#src.distance_transform.calculate_distance_tranform--example-usuage","text":">>> from src.distance_tranform import calculate_distance_tranform >>> segmented_vessels_path = Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/segmentation/vessel/segment___unet___model_file-model' ) >>> calculate_distance_tranform ( study_paths ) >>> output : Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/distance_transform/vessel/distance_tranform___segment___unet___model_file-model' ) Source code in src/distance_transform.py @log_step def calculate_distance_tranform ( data_path : pathlib . PosixPath , stack_size : int = 100 ) -> pathlib . PosixPath : \"\"\" Wrapper function that calculates the distance transform on the segmented blood vessels masks. Due to the size of the data it calculated the distance transform using overlapping cubes. Parameters ---------- **data_path**: *(pathlib.PosixPath)* relative path for the segmented masks to be used for the distance transform **stack_size**: *(int)* TODO: DESCTIBE PROPERLY Returns ------ **output_directory**: *(pathlib.PosixPath) outputs relative path for the folders with calculated distance transform. Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.distance_tranform import calculate_distance_tranform >>>segmented_vessels_path = Path('ppdm/data/5IT_DUMMY_STUDY/results/segmentation/vessel/segment___unet___model_file-model') >>>calculate_distance_tranform(study_paths) >>>output: Path('ppdm/data/5IT_DUMMY_STUDY/results/distance_transform/vessel/distance_tranform___segment___unet___model_file-model') ``` \"\"\" module_results_path = \"results/distance_transform\" module_name = \"distance_tranform\" output_folder_name = join_to_string ([ module_name , data_path . stem ]) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) directory_ok = check_content_of_two_directories ( data_path , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) # step1 - create overlapping bricks submodule_name = \"tmp_overlapping_bricks\" output_folder_name = join_to_string ([ submodule_name , data_path . stem ]) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) if output_directory . exists (): remove_content ( output_directory ) overlapping_bricks = _merge_with_overlap ( data_path , output_directory , stack_size = stack_size ) # step2 - calculate distance transform on overlapping brikcs submodule_name = \"tmp_dt_overlapping_bricks\" output_folder_name = join_to_string ([ submodule_name , data_path . stem ]) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) if output_directory . exists (): remove_content ( output_directory ) overlapping_bricks_dt = _compute_distance_transform ( overlapping_bricks , output_directory ) # step3 - aggregate information from overlapping bricks submodule_name = \"tmp_dt_aggregated_bricks\" output_folder_name = join_to_string ([ submodule_name , data_path . stem ]) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) if output_directory . exists (): remove_content ( output_directory ) aggregated_bricks_dt = _aggregate ( overlapping_bricks_dt , output_directory ) # final step4 - slice bricks back into individual layers output_folder_name = join_to_string ([ module_name , data_path . stem ]) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) if output_directory . exists (): remove_content ( output_directory ) names_of_individual_layers = data_path _split ( aggregated_bricks_dt , output_directory , names_of_individual_layers ) return output_directory","title":"Example Usuage"},{"location":"Modules/preprocessing/","text":"Preprocessing Preprocessing module: Converting Images to numpy form and resizing This module consists of two main functions: convert_images_to_numpy_format data_preprocessing_wrapper convert_images_to_numpy_format ( input_directory ) wrapper function that reduces images in the input folder and converts content of folder to numpy format in parallel (faster) Parameters input_directory : (pathlib.PosixPath object) relative path to the images which should be preprocessed Returns output_directory : (pathlib.PosixPath object) one relative paths for the folder with preprocessed results (tranfered and converted images) Example Usuage >>> from src.preprocessing import convert_images_to_numpy_format >>> tumor_folder = Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/raw/tumor' ) >>> convert_images_to_numpy_format ( tumor_folder ) >>> output : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/tumor' ) Source code in src/preprocessing.py def convert_images_to_numpy_format ( input_directory : pathlib . PosixPath , ) -> pathlib . PosixPath : \"\"\" wrapper function that reduces images in the input folder and converts content of folder to numpy format in parallel (faster) Parameters ---------- **input_directory**: *(pathlib.PosixPath object)* relative path to the images which should be preprocessed Returns ------ **output_directory**: *(pathlib.PosixPath object)* one relative paths for the folder with preprocessed results (tranfered and converted images) Example Usuage -------------- ```python >>>from src.preprocessing import convert_images_to_numpy_format >>>tumor_folder = Path('ppdm/data/5IT_DUMMY_STUDY/source/raw/tumor') >>>convert_images_to_numpy_format(tumor_folder) >>>output: Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/tumor') ``` \"\"\" output_directory = create_preprocessing_relat_directory ( input_directory ) output_directory . mkdir ( parents = True , exist_ok = True ) directory_ok = check_content_of_two_directories ( input_directory , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) parallel_create_numpy_formats_of_input_img = partial ( _create_numpy_formats_of_input_img , output_directory = output_directory , ) parallel ( parallel_create_numpy_formats_of_input_img , sorted ( list ( input_directory . glob ( \"*.tiff\" ))), n_workers = 12 , progress = True , threadpool = True , ) return output_directory data_preprocessing_wrapper ( data ) High level function that covers preprocessing for all data (blood vessels, tumors, virus). It used the convert_images_to_numpy_format function and applies it three times for each channel. If you want to preprocess just one channel (e.g. only tumors) use the convert_images_to_numpy_format function. Parameters data : (dict) containing keys (names of the channels) and values (relative paths to it). Returns preprocessed_data : *(dict) outputs three relative paths for the folders with preprocessed results (tranfered and converted images) Results are dumbed on the disk. Example Usuage >>> from src.preprocessing import data_preprocessing_wrapper >>> study_paths = { 'vessel' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/raw/vessel' ), 'tumor' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/raw/tumor' ), 'virus' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/raw/virus' )} >>> data_preprocessing_wrapper ( study_paths ) >>> output : defaultdict ( < function src . utils . nested_dict () > , { 'vessel' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel' ), 'tumor' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/tumor' ), 'virus' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/virus' )}) Source code in src/preprocessing.py @log_step def data_preprocessing_wrapper ( data : dict ) -> dict : \"\"\" High level function that covers preprocessing for all data (blood vessels, tumors, virus). It used the convert_images_to_numpy_format function and applies it three times for each channel. If you want to preprocess just one channel (e.g. only tumors) use the convert_images_to_numpy_format function. Parameters ---------- **data**: *(dict)* containing keys (names of the channels) and values (relative paths to it). Returns ------ **preprocessed_data**: *(dict) outputs three relative paths for the folders with preprocessed results (tranfered and converted images) Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.preprocessing import data_preprocessing_wrapper >>>study_paths = {'vessel': Path('ppdm/data/5IT_DUMMY_STUDY/source/raw/vessel'), 'tumor': Path('ppdm/data/5IT_DUMMY_STUDY/source/raw/tumor'), 'virus': Path('ppdm/data/5IT_DUMMY_STUDY/source/raw/virus')} >>>data_preprocessing_wrapper(study_paths) >>>output: defaultdict(<function src.utils.nested_dict()>, {'vessel': Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel'), 'tumor': Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/tumor'), 'virus': Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/virus')}) ``` \"\"\" preprocessed_data = nested_dict () out_path = convert_images_to_numpy_format ( data [ \"vessel\" ]) preprocessed_data [ \"vessel\" ] = out_path # tumor out_path = convert_images_to_numpy_format ( data [ \"tumor\" ]) preprocessed_data [ \"tumor\" ] = out_path # virus out_path = convert_images_to_numpy_format ( data [ \"virus\" ]) preprocessed_data [ \"virus\" ] = out_path return preprocessed_data This step will transform and downsize input data ( tumor , vessel , virus ) .tiff files into python's numpy array files, which will be saved to the output path directory. The new folder structure will look as follows: ppdm \u2514\u2500 data \u2514\u2500 5IT_STUDY \u2514\u2500 config.json \u2514\u2500 source \u2514\u2500raw \u2502 \u2514\u2500tumor \u2502 \u2502 \u2514\u2500 5IT-4X_Ch2_z0300.tiff \u2502 \u2502 \u2514\u2500 ... \u2502 \u2502 \u2514\u2500 5IT-4X_Ch2_z1300.tiff \u2502 \u251c\u2500vessel \u2502 \u2502 \u2514\u2500 5IT-4X_Ch3_z0300.tiff \u2502 \u2502 \u2514\u2500 ... \u2502 \u2502 \u2514\u2500 5IT-4X_Ch3_z1300.tiff \u2502 \u2502\u2500virus \u2502 \u2514\u2500 5IT-4X_Ch1_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u25005IT-4X_Ch1_z1300.tiff ------------\u2502------------------------------------------------------- \u2514\u2500transformed \u2514\u2500 np_and_resized \u2514\u2500tumor \u2502 \u2514\u2500 5IT-4X_Ch2_z0300.np \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch2_z1300.np \u251c\u2500vessel \u2502 \u2514\u2500 5IT-4X_Ch3_z0300.np \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch3_z1300.np \u2502\u2500virus \u2514\u2500 5IT-4X_Ch1_z0300.np \u2514\u2500 ... \u2514\u25005IT-4X_Ch1_z1300.np","title":"Preprocessing"},{"location":"Modules/preprocessing/#preprocessing","text":"","title":"Preprocessing"},{"location":"Modules/preprocessing/#src.preprocessing--preprocessing-module","text":"","title":"Preprocessing module:"},{"location":"Modules/preprocessing/#src.preprocessing--converting-images-to-numpy-form-and-resizing","text":"","title":"Converting Images to numpy form and resizing"},{"location":"Modules/preprocessing/#src.preprocessing--this-module-consists-of-two-main-functions","text":"convert_images_to_numpy_format data_preprocessing_wrapper","title":"This module consists of two main functions:"},{"location":"Modules/preprocessing/#src.preprocessing.convert_images_to_numpy_format","text":"wrapper function that reduces images in the input folder and converts content of folder to numpy format in parallel (faster)","title":"convert_images_to_numpy_format()"},{"location":"Modules/preprocessing/#src.preprocessing.convert_images_to_numpy_format--parameters","text":"input_directory : (pathlib.PosixPath object) relative path to the images which should be preprocessed","title":"Parameters"},{"location":"Modules/preprocessing/#src.preprocessing.convert_images_to_numpy_format--returns","text":"output_directory : (pathlib.PosixPath object) one relative paths for the folder with preprocessed results (tranfered and converted images)","title":"Returns"},{"location":"Modules/preprocessing/#src.preprocessing.convert_images_to_numpy_format--example-usuage","text":">>> from src.preprocessing import convert_images_to_numpy_format >>> tumor_folder = Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/raw/tumor' ) >>> convert_images_to_numpy_format ( tumor_folder ) >>> output : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/tumor' ) Source code in src/preprocessing.py def convert_images_to_numpy_format ( input_directory : pathlib . PosixPath , ) -> pathlib . PosixPath : \"\"\" wrapper function that reduces images in the input folder and converts content of folder to numpy format in parallel (faster) Parameters ---------- **input_directory**: *(pathlib.PosixPath object)* relative path to the images which should be preprocessed Returns ------ **output_directory**: *(pathlib.PosixPath object)* one relative paths for the folder with preprocessed results (tranfered and converted images) Example Usuage -------------- ```python >>>from src.preprocessing import convert_images_to_numpy_format >>>tumor_folder = Path('ppdm/data/5IT_DUMMY_STUDY/source/raw/tumor') >>>convert_images_to_numpy_format(tumor_folder) >>>output: Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/tumor') ``` \"\"\" output_directory = create_preprocessing_relat_directory ( input_directory ) output_directory . mkdir ( parents = True , exist_ok = True ) directory_ok = check_content_of_two_directories ( input_directory , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) parallel_create_numpy_formats_of_input_img = partial ( _create_numpy_formats_of_input_img , output_directory = output_directory , ) parallel ( parallel_create_numpy_formats_of_input_img , sorted ( list ( input_directory . glob ( \"*.tiff\" ))), n_workers = 12 , progress = True , threadpool = True , ) return output_directory","title":"Example Usuage"},{"location":"Modules/preprocessing/#src.preprocessing.data_preprocessing_wrapper","text":"High level function that covers preprocessing for all data (blood vessels, tumors, virus). It used the convert_images_to_numpy_format function and applies it three times for each channel. If you want to preprocess just one channel (e.g. only tumors) use the convert_images_to_numpy_format function.","title":"data_preprocessing_wrapper()"},{"location":"Modules/preprocessing/#src.preprocessing.data_preprocessing_wrapper--parameters","text":"data : (dict) containing keys (names of the channels) and values (relative paths to it).","title":"Parameters"},{"location":"Modules/preprocessing/#src.preprocessing.data_preprocessing_wrapper--returns","text":"preprocessed_data : *(dict) outputs three relative paths for the folders with preprocessed results (tranfered and converted images) Results are dumbed on the disk.","title":"Returns"},{"location":"Modules/preprocessing/#src.preprocessing.data_preprocessing_wrapper--example-usuage","text":">>> from src.preprocessing import data_preprocessing_wrapper >>> study_paths = { 'vessel' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/raw/vessel' ), 'tumor' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/raw/tumor' ), 'virus' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/raw/virus' )} >>> data_preprocessing_wrapper ( study_paths ) >>> output : defaultdict ( < function src . utils . nested_dict () > , { 'vessel' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel' ), 'tumor' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/tumor' ), 'virus' : Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/virus' )}) Source code in src/preprocessing.py @log_step def data_preprocessing_wrapper ( data : dict ) -> dict : \"\"\" High level function that covers preprocessing for all data (blood vessels, tumors, virus). It used the convert_images_to_numpy_format function and applies it three times for each channel. If you want to preprocess just one channel (e.g. only tumors) use the convert_images_to_numpy_format function. Parameters ---------- **data**: *(dict)* containing keys (names of the channels) and values (relative paths to it). Returns ------ **preprocessed_data**: *(dict) outputs three relative paths for the folders with preprocessed results (tranfered and converted images) Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.preprocessing import data_preprocessing_wrapper >>>study_paths = {'vessel': Path('ppdm/data/5IT_DUMMY_STUDY/source/raw/vessel'), 'tumor': Path('ppdm/data/5IT_DUMMY_STUDY/source/raw/tumor'), 'virus': Path('ppdm/data/5IT_DUMMY_STUDY/source/raw/virus')} >>>data_preprocessing_wrapper(study_paths) >>>output: defaultdict(<function src.utils.nested_dict()>, {'vessel': Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel'), 'tumor': Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/tumor'), 'virus': Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/virus')}) ``` \"\"\" preprocessed_data = nested_dict () out_path = convert_images_to_numpy_format ( data [ \"vessel\" ]) preprocessed_data [ \"vessel\" ] = out_path # tumor out_path = convert_images_to_numpy_format ( data [ \"tumor\" ]) preprocessed_data [ \"tumor\" ] = out_path # virus out_path = convert_images_to_numpy_format ( data [ \"virus\" ]) preprocessed_data [ \"virus\" ] = out_path return preprocessed_data This step will transform and downsize input data ( tumor , vessel , virus ) .tiff files into python's numpy array files, which will be saved to the output path directory. The new folder structure will look as follows: ppdm \u2514\u2500 data \u2514\u2500 5IT_STUDY \u2514\u2500 config.json \u2514\u2500 source \u2514\u2500raw \u2502 \u2514\u2500tumor \u2502 \u2502 \u2514\u2500 5IT-4X_Ch2_z0300.tiff \u2502 \u2502 \u2514\u2500 ... \u2502 \u2502 \u2514\u2500 5IT-4X_Ch2_z1300.tiff \u2502 \u251c\u2500vessel \u2502 \u2502 \u2514\u2500 5IT-4X_Ch3_z0300.tiff \u2502 \u2502 \u2514\u2500 ... \u2502 \u2502 \u2514\u2500 5IT-4X_Ch3_z1300.tiff \u2502 \u2502\u2500virus \u2502 \u2514\u2500 5IT-4X_Ch1_z0300.tiff \u2502 \u2514\u2500 ... \u2502 \u2514\u25005IT-4X_Ch1_z1300.tiff ------------\u2502------------------------------------------------------- \u2514\u2500transformed \u2514\u2500 np_and_resized \u2514\u2500tumor \u2502 \u2514\u2500 5IT-4X_Ch2_z0300.np \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch2_z1300.np \u251c\u2500vessel \u2502 \u2514\u2500 5IT-4X_Ch3_z0300.np \u2502 \u2514\u2500 ... \u2502 \u2514\u2500 5IT-4X_Ch3_z1300.np \u2502\u2500virus \u2514\u2500 5IT-4X_Ch1_z0300.np \u2514\u2500 ... \u2514\u25005IT-4X_Ch1_z1300.np","title":"Example Usuage"},{"location":"Modules/profiles/","text":"Profiles Profiles module: Computing and Vizualizing final profile This module consists of two main functions: calculate_profile vizualize_profile calculate_profile ( viral_intensity , distance_from_blood_vessel , tumor_mask , pixel_to_microns = 4 , force_overwrite = True ) High level function that calculates profile of viral intensity binned by distance from blood vessel for tumor area. It requires Virus channel, Distance Transform of blood vessels and Tumor masks in order to aggregate the final profile. Parameters viral_intensity : (pathlib.PosixPath) Relative path to the transformed (resized and numpy format) of Virus channel. distance_from_blood_vessel : (pathlib.PosixPath) Relative path to the distance transform arrays calculated from the segmented blood vessels masks. tumor_mask : (pathlib.PosixPath) Relative path to the preprocessed tumor masks. It can also be multi-color masks for the core-periphery separation. pixel_to_microns (float) Ration between pixels and microns. (When Images multiplied by 4) force_overwrite (bool) if true profiles will be recalculated from scratch even if it has been calculated before. Returns Dict : *(dict) dictionary containign the results in a nested form. One Key are profiles calcualted for entire tumor, another are calcualted only for core etc . Example Usuage >>> from src.profiles import calculate_profile >>> viral_intensity = Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/virus' ) >>> distance_from_blood_vessel = Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/distance_transform/vessel/distance_tranform___segment___unet___model_file-model' ) >>> tumor_mask = Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/segmentation_postprocessing/tumor/postprocess_masks___split_tumor_into_core_and_periphery___segment___thresholding___method-th_triangle' ) >>> pixel_to_microns = 4 >>> force_overwrite = False >>> profiles = calculate_profile ( viral_intensity = viral_intensity , distance_from_blood_vessel = distance_from_blood_vessel , tumor_mask = tumor_mask , pixel_to_microns = pixel_to_microns , force_overwrite = force_overwrite ) >>> profiles >>> output : { 'all' : distance virus 4.000000 721.423291 6.648681 721.463944 10.449533 720.214587 14.169995 716.011269 18.046974 715.064906 Source code in src/profiles.py @log_step def calculate_profile ( viral_intensity : pathlib . PosixPath , distance_from_blood_vessel : pathlib . PosixPath , tumor_mask : pathlib . PosixPath , pixel_to_microns : float = 4 , force_overwrite : bool = True , ) -> Dict : \"\"\" High level function that calculates profile of viral intensity binned by distance from blood vessel for tumor area. It requires *Virus* channel, *Distance Transform of blood vessels* and *Tumor masks* in order to aggregate the final profile. Parameters ---------- **viral_intensity**: *(pathlib.PosixPath)* Relative path to the transformed (resized and numpy format) of Virus channel. **distance_from_blood_vessel**: *(pathlib.PosixPath)* Relative path to the distance transform arrays calculated from the segmented blood vessels masks. **tumor_mask**: *(pathlib.PosixPath)* Relative path to the preprocessed tumor masks. It can also be multi-color masks for the core-periphery separation. **pixel_to_microns** *(float)* Ration between pixels and microns. (When Images multiplied by 4) **force_overwrite** *(bool)* if true profiles will be recalculated from scratch even if it has been calculated before. Returns ------ **Dict**: *(dict) dictionary containign the results in a nested form. One Key are profiles calcualted for entire tumor, another are calcualted only for core etc . Example Usuage -------------- ```python >>>from src.profiles import calculate_profile >>>viral_intensity = Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/virus') >>>distance_from_blood_vessel = Path('ppdm/data/5IT_DUMMY_STUDY/results/distance_transform/vessel/distance_tranform___segment___unet___model_file-model') >>>tumor_mask = Path('ppdm/data/5IT_DUMMY_STUDY/results/segmentation_postprocessing/tumor/postprocess_masks___split_tumor_into_core_and_periphery___segment___thresholding___method-th_triangle') >>>pixel_to_microns = 4 >>>force_overwrite=False >>>profiles = calculate_profile( viral_intensity = viral_intensity, distance_from_blood_vessel = distance_from_blood_vessel, tumor_mask = tumor_mask, pixel_to_microns = pixel_to_microns, force_overwrite=force_overwrite) >>>profiles >>>output: {'all': distance virus 4.000000 721.423291 6.648681 721.463944 10.449533 720.214587 14.169995 716.011269 18.046974 715.064906 ``` \"\"\" module_results_path = \"results/profiles\" virus_paths = sorted ( list ( Path ( viral_intensity ) . glob ( \"*\" ))) distance_paths = sorted ( list ( Path ( distance_from_blood_vessel ) . glob ( \"*\" ))) tumor_mask_paths = sorted ( list ( Path ( tumor_mask ) . glob ( \"*\" ))) output_directory = create_relative_path ( viral_intensity , module_results_path , f \" { distance_from_blood_vessel . parts [ - 1 ] } / { tumor_mask . parts [ - 1 ] } /pixel_to_microns- { pixel_to_microns } \" , ) output_file_path = output_directory / \"profiles.pickle\" if output_file_path . exists () and force_overwrite is False : with open ( output_file_path , \"rb\" ) as file : profiles = pickle . load ( file ) else : inputs = [ { \"distance\" : distance , \"virus\" : virus , \"tumor\" : tumor } for distance , virus , tumor in zip ( distance_paths , virus_paths , tumor_mask_paths ) ] profiles_list = parallel ( _profile_data_from_one_layer_wrapper , inputs , n_workers = 12 , progress = True , threadpool = True , ) profiles = _aggregate_profiles ( profiles_list ) # convert distance to microns for key in profiles : profiles [ key ] = rescale_column_pandas ( profiles [ key ], \"distance\" , pixel_to_microns ) profiles [ key ] . reset_index ( drop = True , inplace = True ) # save results with open ( output_file_path , \"wb\" ) as file : pickle . dump ( profiles , file ) return profiles vizualize_profile ( data_frame , distance_threshold_microns = 100 , ylim_bottom = None , plot = True ) Function that vizualizes the aggregated profiles (output of the calculate_profile function) Parameters data_frame : (pd.DataFrame) Dataframe with aggregated profiles to use for the plot distance_threshold_microns : (int) Maximum distance (microns) on the x-axis. ylim_bottom : (float) Minumum values to use in the y-axis. plot (bool) Wheater the profile shuld be plotted or not (usefull when plotting multiple profiles in one cell. Otherwise can be ignored) Returns None Example Usuage >>> from src.profiles import vizualize_profile >>> profile_all = vizualize_profile ( profiles [ \"all\" ]) >>> profile_core = vizualize_profile ( profiles [ \"core\" ]) >>> profile_periphery = vizualize_profile ( profiles [ \"periphery\" ]) Source code in src/profiles.py def vizualize_profile ( data_frame : pd . DataFrame , distance_threshold_microns : int = 100 , ylim_bottom : float = None , plot : bool = True , ) -> plt . figure : \"\"\" Function that vizualizes the aggregated profiles (output of the calculate_profile function) Parameters ---------- **data_frame**: *(pd.DataFrame)* Dataframe with aggregated profiles to use for the plot **distance_threshold_microns**: *(int)* Maximum distance (microns) on the x-axis. **ylim_bottom**: *(float)* Minumum values to use in the y-axis. **plot** *(bool)* Wheater the profile shuld be plotted or not (usefull when plotting multiple profiles in one cell. Otherwise can be ignored) Returns ------ None Example Usuage -------------- ```python >>>from src.profiles import vizualize_profile >>>profile_all = vizualize_profile(profiles[\"all\"]) >>>profile_core = vizualize_profile(profiles[\"core\"]) >>>profile_periphery = vizualize_profile(profiles[\"periphery\"]) ``` \"\"\" profile = data_frame . copy () profile_subset = profile [ profile . distance <= distance_threshold_microns ] # log as figure fig = plt . figure ( figsize = ( 6 , 6 )) plt . rcParams . update ({ \"font.size\" : 12 }) plt . plot ( profile_subset [ \"distance\" ], profile_subset [ \"virus\" ], color = \"black\" ) plt . xlabel ( \"Distance from blood vessel [microns]\" , size = 14 ) plt . ylabel ( \"Viral Intensity\" , size = 14 ) if ylim_bottom is not None : plt . ylim ( bottom = ylim_bottom ) if plot : plt . show () plt . close () return fig","title":"Profiles"},{"location":"Modules/profiles/#profiles","text":"","title":"Profiles"},{"location":"Modules/profiles/#src.profiles--profiles-module","text":"","title":"Profiles module:"},{"location":"Modules/profiles/#src.profiles--computing-and-vizualizing-final-profile","text":"","title":"Computing and Vizualizing final profile"},{"location":"Modules/profiles/#src.profiles--this-module-consists-of-two-main-functions","text":"calculate_profile vizualize_profile","title":"This module consists of two main functions:"},{"location":"Modules/profiles/#src.profiles.calculate_profile","text":"High level function that calculates profile of viral intensity binned by distance from blood vessel for tumor area. It requires Virus channel, Distance Transform of blood vessels and Tumor masks in order to aggregate the final profile.","title":"calculate_profile()"},{"location":"Modules/profiles/#src.profiles.calculate_profile--parameters","text":"viral_intensity : (pathlib.PosixPath) Relative path to the transformed (resized and numpy format) of Virus channel. distance_from_blood_vessel : (pathlib.PosixPath) Relative path to the distance transform arrays calculated from the segmented blood vessels masks. tumor_mask : (pathlib.PosixPath) Relative path to the preprocessed tumor masks. It can also be multi-color masks for the core-periphery separation. pixel_to_microns (float) Ration between pixels and microns. (When Images multiplied by 4) force_overwrite (bool) if true profiles will be recalculated from scratch even if it has been calculated before.","title":"Parameters"},{"location":"Modules/profiles/#src.profiles.calculate_profile--returns","text":"Dict : *(dict) dictionary containign the results in a nested form. One Key are profiles calcualted for entire tumor, another are calcualted only for core etc .","title":"Returns"},{"location":"Modules/profiles/#src.profiles.calculate_profile--example-usuage","text":">>> from src.profiles import calculate_profile >>> viral_intensity = Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/virus' ) >>> distance_from_blood_vessel = Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/distance_transform/vessel/distance_tranform___segment___unet___model_file-model' ) >>> tumor_mask = Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/segmentation_postprocessing/tumor/postprocess_masks___split_tumor_into_core_and_periphery___segment___thresholding___method-th_triangle' ) >>> pixel_to_microns = 4 >>> force_overwrite = False >>> profiles = calculate_profile ( viral_intensity = viral_intensity , distance_from_blood_vessel = distance_from_blood_vessel , tumor_mask = tumor_mask , pixel_to_microns = pixel_to_microns , force_overwrite = force_overwrite ) >>> profiles >>> output : { 'all' : distance virus 4.000000 721.423291 6.648681 721.463944 10.449533 720.214587 14.169995 716.011269 18.046974 715.064906 Source code in src/profiles.py @log_step def calculate_profile ( viral_intensity : pathlib . PosixPath , distance_from_blood_vessel : pathlib . PosixPath , tumor_mask : pathlib . PosixPath , pixel_to_microns : float = 4 , force_overwrite : bool = True , ) -> Dict : \"\"\" High level function that calculates profile of viral intensity binned by distance from blood vessel for tumor area. It requires *Virus* channel, *Distance Transform of blood vessels* and *Tumor masks* in order to aggregate the final profile. Parameters ---------- **viral_intensity**: *(pathlib.PosixPath)* Relative path to the transformed (resized and numpy format) of Virus channel. **distance_from_blood_vessel**: *(pathlib.PosixPath)* Relative path to the distance transform arrays calculated from the segmented blood vessels masks. **tumor_mask**: *(pathlib.PosixPath)* Relative path to the preprocessed tumor masks. It can also be multi-color masks for the core-periphery separation. **pixel_to_microns** *(float)* Ration between pixels and microns. (When Images multiplied by 4) **force_overwrite** *(bool)* if true profiles will be recalculated from scratch even if it has been calculated before. Returns ------ **Dict**: *(dict) dictionary containign the results in a nested form. One Key are profiles calcualted for entire tumor, another are calcualted only for core etc . Example Usuage -------------- ```python >>>from src.profiles import calculate_profile >>>viral_intensity = Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/virus') >>>distance_from_blood_vessel = Path('ppdm/data/5IT_DUMMY_STUDY/results/distance_transform/vessel/distance_tranform___segment___unet___model_file-model') >>>tumor_mask = Path('ppdm/data/5IT_DUMMY_STUDY/results/segmentation_postprocessing/tumor/postprocess_masks___split_tumor_into_core_and_periphery___segment___thresholding___method-th_triangle') >>>pixel_to_microns = 4 >>>force_overwrite=False >>>profiles = calculate_profile( viral_intensity = viral_intensity, distance_from_blood_vessel = distance_from_blood_vessel, tumor_mask = tumor_mask, pixel_to_microns = pixel_to_microns, force_overwrite=force_overwrite) >>>profiles >>>output: {'all': distance virus 4.000000 721.423291 6.648681 721.463944 10.449533 720.214587 14.169995 716.011269 18.046974 715.064906 ``` \"\"\" module_results_path = \"results/profiles\" virus_paths = sorted ( list ( Path ( viral_intensity ) . glob ( \"*\" ))) distance_paths = sorted ( list ( Path ( distance_from_blood_vessel ) . glob ( \"*\" ))) tumor_mask_paths = sorted ( list ( Path ( tumor_mask ) . glob ( \"*\" ))) output_directory = create_relative_path ( viral_intensity , module_results_path , f \" { distance_from_blood_vessel . parts [ - 1 ] } / { tumor_mask . parts [ - 1 ] } /pixel_to_microns- { pixel_to_microns } \" , ) output_file_path = output_directory / \"profiles.pickle\" if output_file_path . exists () and force_overwrite is False : with open ( output_file_path , \"rb\" ) as file : profiles = pickle . load ( file ) else : inputs = [ { \"distance\" : distance , \"virus\" : virus , \"tumor\" : tumor } for distance , virus , tumor in zip ( distance_paths , virus_paths , tumor_mask_paths ) ] profiles_list = parallel ( _profile_data_from_one_layer_wrapper , inputs , n_workers = 12 , progress = True , threadpool = True , ) profiles = _aggregate_profiles ( profiles_list ) # convert distance to microns for key in profiles : profiles [ key ] = rescale_column_pandas ( profiles [ key ], \"distance\" , pixel_to_microns ) profiles [ key ] . reset_index ( drop = True , inplace = True ) # save results with open ( output_file_path , \"wb\" ) as file : pickle . dump ( profiles , file ) return profiles","title":"Example Usuage"},{"location":"Modules/profiles/#src.profiles.vizualize_profile","text":"Function that vizualizes the aggregated profiles (output of the calculate_profile function)","title":"vizualize_profile()"},{"location":"Modules/profiles/#src.profiles.vizualize_profile--parameters","text":"data_frame : (pd.DataFrame) Dataframe with aggregated profiles to use for the plot distance_threshold_microns : (int) Maximum distance (microns) on the x-axis. ylim_bottom : (float) Minumum values to use in the y-axis. plot (bool) Wheater the profile shuld be plotted or not (usefull when plotting multiple profiles in one cell. Otherwise can be ignored)","title":"Parameters"},{"location":"Modules/profiles/#src.profiles.vizualize_profile--returns","text":"None","title":"Returns"},{"location":"Modules/profiles/#src.profiles.vizualize_profile--example-usuage","text":">>> from src.profiles import vizualize_profile >>> profile_all = vizualize_profile ( profiles [ \"all\" ]) >>> profile_core = vizualize_profile ( profiles [ \"core\" ]) >>> profile_periphery = vizualize_profile ( profiles [ \"periphery\" ]) Source code in src/profiles.py def vizualize_profile ( data_frame : pd . DataFrame , distance_threshold_microns : int = 100 , ylim_bottom : float = None , plot : bool = True , ) -> plt . figure : \"\"\" Function that vizualizes the aggregated profiles (output of the calculate_profile function) Parameters ---------- **data_frame**: *(pd.DataFrame)* Dataframe with aggregated profiles to use for the plot **distance_threshold_microns**: *(int)* Maximum distance (microns) on the x-axis. **ylim_bottom**: *(float)* Minumum values to use in the y-axis. **plot** *(bool)* Wheater the profile shuld be plotted or not (usefull when plotting multiple profiles in one cell. Otherwise can be ignored) Returns ------ None Example Usuage -------------- ```python >>>from src.profiles import vizualize_profile >>>profile_all = vizualize_profile(profiles[\"all\"]) >>>profile_core = vizualize_profile(profiles[\"core\"]) >>>profile_periphery = vizualize_profile(profiles[\"periphery\"]) ``` \"\"\" profile = data_frame . copy () profile_subset = profile [ profile . distance <= distance_threshold_microns ] # log as figure fig = plt . figure ( figsize = ( 6 , 6 )) plt . rcParams . update ({ \"font.size\" : 12 }) plt . plot ( profile_subset [ \"distance\" ], profile_subset [ \"virus\" ], color = \"black\" ) plt . xlabel ( \"Distance from blood vessel [microns]\" , size = 14 ) plt . ylabel ( \"Viral Intensity\" , size = 14 ) if ylim_bottom is not None : plt . ylim ( bottom = ylim_bottom ) if plot : plt . show () plt . close () return fig","title":"Example Usuage"},{"location":"Modules/segmentation/","text":"Segmentation Some segmentation models (random_forest and unet) require a pre-trained model as a function argument. All pre-trained model can be found within the 3DHistology folder on the HPC server at this link: /SFS/project/ry/3DHistology/pretrained_models. segmentation module: module for blood vessels and tumor segmentation This module consists of four main functions: random_forest segmentation_wrapper thresholding unet random_forest ( data_path , output_directory , model_file ) Function that performs the segmentation of the blood vessels using Random Forest model (if you want to segment e.g. tumors this function can still be used. However, you need to provide a pre-trained model (model_file) that is pretrained for tumors) Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided. Parameters data_path : (pathlib.PosixPath object) relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) output_directory (pathlib.PosixPath object) relative path to a folder where the results should be saved model_file : (pathlib.PosixPath object) relative path to the pre-trained model binary file, which should be used for the segmentation Returns None: Results are dumbed on the disk. Example Usuage >>> from src.segmentation import random_forest >>> random_forest ( data_path = Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel' ), output_directory = Path ( 'ppdm/data/5IT_DUMMY_STUDY/RF/raw/vessel' ), model_file = Path ( 'pretrained_models/rf_model.joblib' ) ) Source code in src/segmentation.py @log_step def random_forest ( data_path : pathlib . PosixPath , output_directory : pathlib . PosixPath , model_file , ) -> None : \"\"\" Function that performs the segmentation of the blood vessels using Random Forest model (if you want to segment e.g. tumors this function can still be used. However, you need to provide a pre-trained model (model_file) that is pretrained for tumors) Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided. Parameters ---------- **data_path**: *(pathlib.PosixPath object)* relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) **output_directory** *(pathlib.PosixPath object)* relative path to a folder where the results should be saved **model_file**: *(pathlib.PosixPath object)* relative path to the pre-trained model binary file, which should be used for the segmentation Returns ------ None: Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.segmentation import random_forest >>>random_forest( data_path = Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel'), output_directory = Path('ppdm/data/5IT_DUMMY_STUDY/RF/raw/vessel'), model_file = Path('pretrained_models/rf_model.joblib') ) ``` \"\"\" loaded_rf = load ( model_file ) segment_rf_partial = partial ( _segment_random_forest , loaded_estimator_to_use = loaded_rf , output_directory = output_directory , ) directory_ok = check_content_of_two_directories ( data_path , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) parallel ( segment_rf_partial , sorted ( list ( data_path . glob ( \"*.npy\" ))), n_workers = 12 , progress = True , threadpool = True , ) segmentation_wrapper ( data_path , method , method_parameters ) This function is a main wrapper for segmentation used within the automated pipeline. It uses functions written in this script and wraps them in this wrapper (one big function). If one want to use segmentations methods in a script, you may use individual segmentation functions -> unet, thresholding, random_forest Parameters data_path : (pathlib.PosixPath object) relative path to the study which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) method : (str) method to use for segmentation (unet, thresholding, random_forest) method_parameters : (Dict) relative path to the pre-trained model binary file, which should be used for the segmentation device : (str) graphic card which should be used. Code automatically selects graphic card, that is free. Returns None: Results are dumbed on the disk. Example Usuage >>> from src.segmentation import unet >>> unet ( input_directory = Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel' ), output_directory = Path ( 'ppdm/data/5IT_DUMMY_STUDY/DOCUMENTATION/raw/vessel' ), model_file = Path ( 'pretrained_models/unet_train_full_5IT_7IV_8IV.pt' ) ) Source code in src/segmentation.py @log_step def segmentation_wrapper ( data_path : pathlib . PosixPath , method : str , method_parameters : Dict ) -> pathlib . PosixPath : \"\"\" This function is a main wrapper for segmentation used within the automated pipeline. It uses functions written in this script and wraps them in this wrapper (one big function). If one want to use segmentations methods in a script, you may use individual segmentation functions -> unet, thresholding, random_forest Parameters ---------- **data_path** : *(pathlib.PosixPath object)* relative path to the study which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) **method** : *(str)* method to use for segmentation (unet, thresholding, random_forest) **method_parameters**: *(Dict)* relative path to the pre-trained model binary file, which should be used for the segmentation **device**: *(str)* graphic card which should be used. Code automatically selects graphic card, that is free. Returns ------ None: Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.segmentation import unet >>>unet( input_directory = Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel'), output_directory = Path('ppdm/data/5IT_DUMMY_STUDY/DOCUMENTATION/raw/vessel'), model_file = Path('pretrained_models/unet_train_full_5IT_7IV_8IV.pt') ) ``` \"\"\" module_results_path = \"results/segmentation\" module_name = \"segment\" segmentation_function = _select_method ( method ) parameters_as_string = join_keys_and_values_to_list ( method_parameters ) output_folder_name = join_to_string ( [ module_name , method , * parameters_as_string ] ) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name ) directory_ok = check_content_of_two_directories ( data_path , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) segmentation_function ( data_path , output_directory , ** method_parameters ) return output_directory thresholding ( data_path , output_directory , method , mask_path = None ) Function that performs the segmentation using thresholding. This function can be used for any channel (e.g. vessels, tumors) as it calculates \"optimal\" threshold value automatically. Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided. Parameters data_path : (pathlib.PosixPath object) relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) output_directory (pathlib.PosixPath object) relative path to a folder where the results should be saved method : (str) segmentation method to be used. Supported methods are \"th_otsu\", \"th_triangle\", \"th_yen\". ANOTHER OPTIONAL PARAMETERS: mask_path : (pathlib.PosixPath object) relative path for the binary mask to be used to filter the area of interest on which the segmentation will be performed. Returns None: Results are dumbed on the disk. Example Usuage >>> from src.segmentation import thresholding >>> thresholding ( data_path = Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel' ), output_directory = Path ( 'msd_projects/ppdm/data/5IT_DUMMY_STUDY/THRES/raw/vessel' ), method = \"th_otsu\" ) Source code in src/segmentation.py @log_step def thresholding ( data_path : pathlib . PosixPath , output_directory : pathlib . PosixPath , method : str , mask_path : pathlib . PosixPath = None , ) -> None : \"\"\" Function that performs the segmentation using thresholding. This function can be used for any channel (e.g. vessels, tumors) as it calculates \"optimal\" threshold value automatically. Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided. Parameters ---------- **data_path**: *(pathlib.PosixPath object)* relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) **output_directory** *(pathlib.PosixPath object)* relative path to a folder where the results should be saved **method**: *(str)* segmentation method to be used. Supported methods are \"th_otsu\", \"th_triangle\", \"th_yen\". ANOTHER OPTIONAL PARAMETERS: **mask_path**: *(pathlib.PosixPath object)* relative path for the binary mask to be used to filter the area of interest on which the segmentation will be performed. Returns ------ None: Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.segmentation import thresholding >>>thresholding( data_path = Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel'), output_directory = Path('msd_projects/ppdm/data/5IT_DUMMY_STUDY/THRES/raw/vessel'), method = \"th_otsu\" ) ``` \"\"\" supported_methods = [ \"th_otsu\" , \"th_triangle\" , \"th_yen\" ] if method not in supported_methods : raise ValueError ( f \"thresholding method must be either in : { supported_methods } , you have provided: { method } \" ) threshold_value = _calculate_threshold_value ( data_path , method , mask_path ) print ( f \"threshold { method } value: { threshold_value } \" ) _segment_and_save_masks_threshold ( data_path , threshold_value , output_directory ) unet ( input_directory , output_directory , model_file , device = None ) Function that performs the segmentation of the blood vessels (if you want to segment e.g. tumors this function can still be used. However, you need to provide a pre-trained model (model_file) that is pretrained for tumors) Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided. Parameters input_directory : (pathlib.PosixPath object) relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) output_directory : (pathlib.PosixPath object) relative path to a folder where the results should be saved model_file : (pathlib.PosixPath object) relative path to the pre-trained model binary file, which should be used for the segmentation device : (str) graphic card which should be used. Code automatically selects graphic card, that is free. Returns None: Results are dumbed on the disk. Example Usuage >>> from src.segmentation import unet >>> unet ( input_directory = Path ( 'msd_projects/ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel' ), output_directory = Path ( 'msd_projects/ppdm/data/5IT_DUMMY_STUDY/DOCUMENTATION/raw/vessel' ), model_file = Path ( 'pretrained_models/unet_train_full_5IT_7IV_8IV.pt' ) ) Source code in src/segmentation.py @log_step def unet ( input_directory : pathlib . PosixPath , output_directory : pathlib . PosixPath , model_file : pathlib . PosixPath , device : str = None , ) -> None : \"\"\" Function that performs the segmentation of the blood vessels (if you want to segment e.g. tumors this function can still be used. However, you need to provide a pre-trained model (model_file) that is pretrained for tumors) Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided. Parameters ---------- **input_directory** : *(pathlib.PosixPath object)* relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) **output_directory** : *(pathlib.PosixPath object)* relative path to a folder where the results should be saved **model_file**: *(pathlib.PosixPath object)* relative path to the pre-trained model binary file, which should be used for the segmentation **device**: *(str)* graphic card which should be used. Code automatically selects graphic card, that is free. Returns ------ None: Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.segmentation import unet >>>unet( input_directory = Path('msd_projects/ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel'), output_directory = Path('msd_projects/ppdm/data/5IT_DUMMY_STUDY/DOCUMENTATION/raw/vessel'), model_file = Path('pretrained_models/unet_train_full_5IT_7IV_8IV.pt') ) ``` \"\"\" input_directory_paths = sorted ( list ( input_directory . glob ( \"*.npy\" ))) directory_ok = check_content_of_two_directories ( input_directory , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) if device is None : device = f \"cuda: { select_avail_gpu () } \" model = torch . load ( model_file ) model = model . to ( device ) . eval () for file in tqdm ( input_directory_paths ): image = np . load ( file ) # convert 16 bit images to 8bits if image . dtype == \"uint16\" : image = image / 65535 * 255 image = image . astype ( np . uint8 ) image = np . expand_dims ( image , axis = 0 ) # split images to tiles tiler = VolumeSlicer ( image . shape , voxel_size = ( image . shape [ 0 ], 512 , 512 ), voxel_step = ( image . shape [ 0 ], 512 , 512 ), ) tiles = tiler . split ( image ) tiles_processed = _unet_runner ( tiles , model , device ) # merge tiles back to one image tiles_stiched = tiler . merge ( tiles_processed ) mask = tiles_stiched [ 0 , :, :] # save mask save_path_mask = output_directory / file . name output_directory . mkdir ( parents = True , exist_ok = True ) np . save ( save_path_mask , mask . astype ( np . uint8 ))","title":"Segmentation"},{"location":"Modules/segmentation/#segmentation","text":"Some segmentation models (random_forest and unet) require a pre-trained model as a function argument. All pre-trained model can be found within the 3DHistology folder on the HPC server at this link: /SFS/project/ry/3DHistology/pretrained_models.","title":"Segmentation"},{"location":"Modules/segmentation/#src.segmentation--segmentation-module","text":"","title":"segmentation module:"},{"location":"Modules/segmentation/#src.segmentation--module-for-blood-vessels-and-tumor-segmentation","text":"","title":"module for blood vessels and tumor segmentation"},{"location":"Modules/segmentation/#src.segmentation--this-module-consists-of-four-main-functions","text":"random_forest segmentation_wrapper thresholding unet","title":"This module consists of four main functions:"},{"location":"Modules/segmentation/#src.segmentation.random_forest","text":"Function that performs the segmentation of the blood vessels using Random Forest model (if you want to segment e.g. tumors this function can still be used. However, you need to provide a pre-trained model (model_file) that is pretrained for tumors) Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided.","title":"random_forest()"},{"location":"Modules/segmentation/#src.segmentation.random_forest--parameters","text":"data_path : (pathlib.PosixPath object) relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) output_directory (pathlib.PosixPath object) relative path to a folder where the results should be saved model_file : (pathlib.PosixPath object) relative path to the pre-trained model binary file, which should be used for the segmentation","title":"Parameters"},{"location":"Modules/segmentation/#src.segmentation.random_forest--returns","text":"None: Results are dumbed on the disk.","title":"Returns"},{"location":"Modules/segmentation/#src.segmentation.random_forest--example-usuage","text":">>> from src.segmentation import random_forest >>> random_forest ( data_path = Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel' ), output_directory = Path ( 'ppdm/data/5IT_DUMMY_STUDY/RF/raw/vessel' ), model_file = Path ( 'pretrained_models/rf_model.joblib' ) ) Source code in src/segmentation.py @log_step def random_forest ( data_path : pathlib . PosixPath , output_directory : pathlib . PosixPath , model_file , ) -> None : \"\"\" Function that performs the segmentation of the blood vessels using Random Forest model (if you want to segment e.g. tumors this function can still be used. However, you need to provide a pre-trained model (model_file) that is pretrained for tumors) Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided. Parameters ---------- **data_path**: *(pathlib.PosixPath object)* relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) **output_directory** *(pathlib.PosixPath object)* relative path to a folder where the results should be saved **model_file**: *(pathlib.PosixPath object)* relative path to the pre-trained model binary file, which should be used for the segmentation Returns ------ None: Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.segmentation import random_forest >>>random_forest( data_path = Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel'), output_directory = Path('ppdm/data/5IT_DUMMY_STUDY/RF/raw/vessel'), model_file = Path('pretrained_models/rf_model.joblib') ) ``` \"\"\" loaded_rf = load ( model_file ) segment_rf_partial = partial ( _segment_random_forest , loaded_estimator_to_use = loaded_rf , output_directory = output_directory , ) directory_ok = check_content_of_two_directories ( data_path , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) parallel ( segment_rf_partial , sorted ( list ( data_path . glob ( \"*.npy\" ))), n_workers = 12 , progress = True , threadpool = True , )","title":"Example Usuage"},{"location":"Modules/segmentation/#src.segmentation.segmentation_wrapper","text":"This function is a main wrapper for segmentation used within the automated pipeline. It uses functions written in this script and wraps them in this wrapper (one big function). If one want to use segmentations methods in a script, you may use individual segmentation functions -> unet, thresholding, random_forest","title":"segmentation_wrapper()"},{"location":"Modules/segmentation/#src.segmentation.segmentation_wrapper--parameters","text":"data_path : (pathlib.PosixPath object) relative path to the study which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) method : (str) method to use for segmentation (unet, thresholding, random_forest) method_parameters : (Dict) relative path to the pre-trained model binary file, which should be used for the segmentation device : (str) graphic card which should be used. Code automatically selects graphic card, that is free.","title":"Parameters"},{"location":"Modules/segmentation/#src.segmentation.segmentation_wrapper--returns","text":"None: Results are dumbed on the disk.","title":"Returns"},{"location":"Modules/segmentation/#src.segmentation.segmentation_wrapper--example-usuage","text":">>> from src.segmentation import unet >>> unet ( input_directory = Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel' ), output_directory = Path ( 'ppdm/data/5IT_DUMMY_STUDY/DOCUMENTATION/raw/vessel' ), model_file = Path ( 'pretrained_models/unet_train_full_5IT_7IV_8IV.pt' ) ) Source code in src/segmentation.py @log_step def segmentation_wrapper ( data_path : pathlib . PosixPath , method : str , method_parameters : Dict ) -> pathlib . PosixPath : \"\"\" This function is a main wrapper for segmentation used within the automated pipeline. It uses functions written in this script and wraps them in this wrapper (one big function). If one want to use segmentations methods in a script, you may use individual segmentation functions -> unet, thresholding, random_forest Parameters ---------- **data_path** : *(pathlib.PosixPath object)* relative path to the study which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) **method** : *(str)* method to use for segmentation (unet, thresholding, random_forest) **method_parameters**: *(Dict)* relative path to the pre-trained model binary file, which should be used for the segmentation **device**: *(str)* graphic card which should be used. Code automatically selects graphic card, that is free. Returns ------ None: Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.segmentation import unet >>>unet( input_directory = Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel'), output_directory = Path('ppdm/data/5IT_DUMMY_STUDY/DOCUMENTATION/raw/vessel'), model_file = Path('pretrained_models/unet_train_full_5IT_7IV_8IV.pt') ) ``` \"\"\" module_results_path = \"results/segmentation\" module_name = \"segment\" segmentation_function = _select_method ( method ) parameters_as_string = join_keys_and_values_to_list ( method_parameters ) output_folder_name = join_to_string ( [ module_name , method , * parameters_as_string ] ) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name ) directory_ok = check_content_of_two_directories ( data_path , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) segmentation_function ( data_path , output_directory , ** method_parameters ) return output_directory","title":"Example Usuage"},{"location":"Modules/segmentation/#src.segmentation.thresholding","text":"Function that performs the segmentation using thresholding. This function can be used for any channel (e.g. vessels, tumors) as it calculates \"optimal\" threshold value automatically. Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided.","title":"thresholding()"},{"location":"Modules/segmentation/#src.segmentation.thresholding--parameters","text":"data_path : (pathlib.PosixPath object) relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) output_directory (pathlib.PosixPath object) relative path to a folder where the results should be saved method : (str) segmentation method to be used. Supported methods are \"th_otsu\", \"th_triangle\", \"th_yen\". ANOTHER OPTIONAL PARAMETERS: mask_path : (pathlib.PosixPath object) relative path for the binary mask to be used to filter the area of interest on which the segmentation will be performed.","title":"Parameters"},{"location":"Modules/segmentation/#src.segmentation.thresholding--returns","text":"None: Results are dumbed on the disk.","title":"Returns"},{"location":"Modules/segmentation/#src.segmentation.thresholding--example-usuage","text":">>> from src.segmentation import thresholding >>> thresholding ( data_path = Path ( 'ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel' ), output_directory = Path ( 'msd_projects/ppdm/data/5IT_DUMMY_STUDY/THRES/raw/vessel' ), method = \"th_otsu\" ) Source code in src/segmentation.py @log_step def thresholding ( data_path : pathlib . PosixPath , output_directory : pathlib . PosixPath , method : str , mask_path : pathlib . PosixPath = None , ) -> None : \"\"\" Function that performs the segmentation using thresholding. This function can be used for any channel (e.g. vessels, tumors) as it calculates \"optimal\" threshold value automatically. Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided. Parameters ---------- **data_path**: *(pathlib.PosixPath object)* relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) **output_directory** *(pathlib.PosixPath object)* relative path to a folder where the results should be saved **method**: *(str)* segmentation method to be used. Supported methods are \"th_otsu\", \"th_triangle\", \"th_yen\". ANOTHER OPTIONAL PARAMETERS: **mask_path**: *(pathlib.PosixPath object)* relative path for the binary mask to be used to filter the area of interest on which the segmentation will be performed. Returns ------ None: Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.segmentation import thresholding >>>thresholding( data_path = Path('ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel'), output_directory = Path('msd_projects/ppdm/data/5IT_DUMMY_STUDY/THRES/raw/vessel'), method = \"th_otsu\" ) ``` \"\"\" supported_methods = [ \"th_otsu\" , \"th_triangle\" , \"th_yen\" ] if method not in supported_methods : raise ValueError ( f \"thresholding method must be either in : { supported_methods } , you have provided: { method } \" ) threshold_value = _calculate_threshold_value ( data_path , method , mask_path ) print ( f \"threshold { method } value: { threshold_value } \" ) _segment_and_save_masks_threshold ( data_path , threshold_value , output_directory )","title":"Example Usuage"},{"location":"Modules/segmentation/#src.segmentation.unet","text":"Function that performs the segmentation of the blood vessels (if you want to segment e.g. tumors this function can still be used. However, you need to provide a pre-trained model (model_file) that is pretrained for tumors) Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided.","title":"unet()"},{"location":"Modules/segmentation/#src.segmentation.unet--parameters","text":"input_directory : (pathlib.PosixPath object) relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) output_directory : (pathlib.PosixPath object) relative path to a folder where the results should be saved model_file : (pathlib.PosixPath object) relative path to the pre-trained model binary file, which should be used for the segmentation device : (str) graphic card which should be used. Code automatically selects graphic card, that is free.","title":"Parameters"},{"location":"Modules/segmentation/#src.segmentation.unet--returns","text":"None: Results are dumbed on the disk.","title":"Returns"},{"location":"Modules/segmentation/#src.segmentation.unet--example-usuage","text":">>> from src.segmentation import unet >>> unet ( input_directory = Path ( 'msd_projects/ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel' ), output_directory = Path ( 'msd_projects/ppdm/data/5IT_DUMMY_STUDY/DOCUMENTATION/raw/vessel' ), model_file = Path ( 'pretrained_models/unet_train_full_5IT_7IV_8IV.pt' ) ) Source code in src/segmentation.py @log_step def unet ( input_directory : pathlib . PosixPath , output_directory : pathlib . PosixPath , model_file : pathlib . PosixPath , device : str = None , ) -> None : \"\"\" Function that performs the segmentation of the blood vessels (if you want to segment e.g. tumors this function can still be used. However, you need to provide a pre-trained model (model_file) that is pretrained for tumors) Function performs the segmentation and saves the results (individual segmented images) to the output_directory path provided. Parameters ---------- **input_directory** : *(pathlib.PosixPath object)* relative path to the images which should be segmented (notice that we work with preprocessed images which are in npy for and not in .tiff format) **output_directory** : *(pathlib.PosixPath object)* relative path to a folder where the results should be saved **model_file**: *(pathlib.PosixPath object)* relative path to the pre-trained model binary file, which should be used for the segmentation **device**: *(str)* graphic card which should be used. Code automatically selects graphic card, that is free. Returns ------ None: Results are dumbed on the disk. Example Usuage -------------- ```python >>>from src.segmentation import unet >>>unet( input_directory = Path('msd_projects/ppdm/data/5IT_DUMMY_STUDY/source/transformed/np_and_resized/vessel'), output_directory = Path('msd_projects/ppdm/data/5IT_DUMMY_STUDY/DOCUMENTATION/raw/vessel'), model_file = Path('pretrained_models/unet_train_full_5IT_7IV_8IV.pt') ) ``` \"\"\" input_directory_paths = sorted ( list ( input_directory . glob ( \"*.npy\" ))) directory_ok = check_content_of_two_directories ( input_directory , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) if device is None : device = f \"cuda: { select_avail_gpu () } \" model = torch . load ( model_file ) model = model . to ( device ) . eval () for file in tqdm ( input_directory_paths ): image = np . load ( file ) # convert 16 bit images to 8bits if image . dtype == \"uint16\" : image = image / 65535 * 255 image = image . astype ( np . uint8 ) image = np . expand_dims ( image , axis = 0 ) # split images to tiles tiler = VolumeSlicer ( image . shape , voxel_size = ( image . shape [ 0 ], 512 , 512 ), voxel_step = ( image . shape [ 0 ], 512 , 512 ), ) tiles = tiler . split ( image ) tiles_processed = _unet_runner ( tiles , model , device ) # merge tiles back to one image tiles_stiched = tiler . merge ( tiles_processed ) mask = tiles_stiched [ 0 , :, :] # save mask save_path_mask = output_directory / file . name output_directory . mkdir ( parents = True , exist_ok = True ) np . save ( save_path_mask , mask . astype ( np . uint8 ))","title":"Example Usuage"},{"location":"Modules/segmentation_postprocessing/","text":"Segmentation Postprocessing segmentation postprocessing module: module for certain masks postprocessing operation Implemented Operations: Reducing Tumor Borders and Filling holes This module consists of four main functions: postprocess_masks split_tumor_into_core_and_periphery postprocess_masks ( data_path , method , method_parameters ) Wrapper function, which handles the masks postprocessing within the pipeline. For now only used for the tumor masks postprocessing to split masks into core and periphery regions. Parameters data_path : (pathlib.PosixPath) relative path to the segmented masks. method : (str) function which should be apply in order to postprocess masks. Thus far we only use 'split_tumor_into_core_and_periphery' function. method_parameters : (Dict) parameters to use for the function applied in method argument. Returns output_directory (pathlib.PosixPath) : Path where the results have been dumped on the disk to. Example Usuage >>> from src.segmentation import postprocess_masks >>> postprocess_masks ( input_directory = Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/segmentation/tumor/segment___thresholding___method-th_triangle' ), method = 'split_tumor_into_core_and_periphery' , method_parameters = { 'periphery_as_ratio_of_max_distance' : 0.6 } Source code in src/segmentation_postprocessing.py @log_step def postprocess_masks ( data_path : pathlib . PosixPath , method : str , method_parameters : Dict ) -> pathlib . PosixPath : \"\"\" Wrapper function, which handles the masks postprocessing within the pipeline. For now only used for the tumor masks postprocessing to split masks into core and periphery regions. Parameters ---------- **data_path** : *(pathlib.PosixPath)* relative path to the segmented masks. **method**: *(str)* function which should be apply in order to postprocess masks. Thus far we only use 'split_tumor_into_core_and_periphery' function. **method_parameters**: *(Dict)* parameters to use for the function applied in **method** argument. Returns ------ output_directory *(pathlib.PosixPath)*: Path where the results have been dumped on the disk to. Example Usuage -------------- ```python >>>from src.segmentation import postprocess_masks >>>postprocess_masks( input_directory = Path('ppdm/data/5IT_DUMMY_STUDY/results/segmentation/tumor/segment___thresholding___method-th_triangle'), method = 'split_tumor_into_core_and_periphery', method_parameters = {'periphery_as_ratio_of_max_distance': 0.6} ``` \"\"\" module_results_path = \"results/segmentation_postprocessing\" module_name = \"postprocess_masks\" segmentation_postprocessing_function = getattr ( sys . modules [ __name__ ], method ) parameters_as_string = join_keys_and_values_to_list ( method_parameters ) output_folder_name = join_to_string ( [ module_name , method , * parameters_as_string , data_path . stem ] ) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) directory_ok = check_content_of_two_directories ( data_path , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) segmentation_postprocessing_function ( data_path , output_directory , ** method_parameters ) return output_directory split_tumor_into_core_and_periphery ( input_directory , output_directory , periphery_as_ratio_of_max_distance = 0.2 ) Function which splits tumor into core and periphery based on relative distance from the surface. Parameters input_directory : (pathlib.PosixPath) relative path to the segmented masks. output_directory : (pathlib.PosixPath) relative path where the results should be saved to. periphery_as_ratio_of_max_distance : (float) what ratio of the tumor should be consired core. Any number in <0;1> Returns None: Results are dumped on the disk. Example Usuage >>> from src.segmentation import split_tumor_into_core_and_periphery >>> split_tumor_into_core_and_periphery ( input_directory = Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/segmentation/tumor/segment___thresholding___method-th_triangle' ), output_directory = Path ( 'ppdm/data/my_tumor_folder' ), periphery_as_ratio_of_max_distance = 0.5 ) Source code in src/segmentation_postprocessing.py def split_tumor_into_core_and_periphery ( input_directory : pathlib . PosixPath , output_directory : pathlib . PosixPath , periphery_as_ratio_of_max_distance : float = 0.2 , ) -> None : \"\"\" Function which splits tumor into core and periphery based on relative distance from the surface. Parameters ---------- **input_directory** : *(pathlib.PosixPath)* relative path to the segmented masks. **output_directory** : *(pathlib.PosixPath)* relative path where the results should be saved to. **periphery_as_ratio_of_max_distance**: *(float)* what ratio of the tumor should be consired core. Any number in <0;1> Returns ------ None: Results are dumped on the disk. Example Usuage -------------- ```python >>>from src.segmentation import split_tumor_into_core_and_periphery >>>split_tumor_into_core_and_periphery( input_directory = Path('ppdm/data/5IT_DUMMY_STUDY/results/segmentation/tumor/segment___thresholding___method-th_triangle'), output_directory = Path('ppdm/data/my_tumor_folder'), periphery_as_ratio_of_max_distance = 0.5) ``` \"\"\" original_images = sorted ( list ( input_directory . glob ( \"*.npy\" ))) imgs_tumor_mask_list = parallel ( _load_and_transform_image , original_images , n_workers = 12 , threadpool = True , progress = True , ) # check if layers (baesed on image names) are ordered correctly layer_names = [ x [ \"name\" ] for x in imgs_tumor_mask_list ] imgs_tum = _stack_and_downscale_images ( imgs_tumor_mask_list ) # do distance transform imgs_tum_dt = edt . edt ( imgs_tum , black_border = False , parallel = 12 , order = \"C\" ) # split masked object into core and periphery based on distance from surface distance_threshold = periphery_as_ratio_of_max_distance * np . max ( imgs_tum_dt ) imgs_outer = np . where ( imgs_tum_dt < distance_threshold , imgs_tum_dt , 0 ,) # inner mask # make sure inner mask is binary outer_mask = np . where ( imgs_outer > 0 , 1 , 0 ) # outer mask inner_mask = imgs_tum - outer_mask # resize z-axis back to original inner_mask = zoom ( inner_mask , ( 10 , 1 , 1 ), mode = \"nearest\" , order = 0 ) outer_mask = zoom ( outer_mask , ( 10 , 1 , 1 ), mode = \"nearest\" , order = 0 ) # save to disk mask_path = output_directory mask_path . parent . mkdir ( exist_ok = True , parents = True ) inner_mask_iterable = [ x for x in inner_mask ] outer_mask_iterable = [ x for x in outer_mask ] inner_outer_mask_individual_layers = [ { \"name\" : layer_name , \"image_path\" : layer_image , \"core_periphery\" : core_periphery , } for layer_name , layer_image , core_periphery in zip ( layer_names , original_images , zip ( inner_mask_iterable , outer_mask_iterable ), ) ] parallel ( partial ( _encode_combine_transform_and_save_mask , output_directory = mask_path ), inner_outer_mask_individual_layers , n_workers = 12 , progress = True , threadpool = True , )","title":"Segmentation Postprocessing"},{"location":"Modules/segmentation_postprocessing/#segmentation-postprocessing","text":"","title":"Segmentation Postprocessing"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing--segmentation-postprocessing-module","text":"","title":"segmentation postprocessing module:"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing--module-for-certain-masks-postprocessing-operation","text":"","title":"module for certain masks postprocessing operation"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing--implemented-operations-reducing-tumor-borders-and-filling-holes","text":"","title":"Implemented Operations: Reducing Tumor Borders and Filling holes"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing--this-module-consists-of-four-main-functions","text":"postprocess_masks split_tumor_into_core_and_periphery","title":"This module consists of four main functions:"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing.postprocess_masks","text":"Wrapper function, which handles the masks postprocessing within the pipeline. For now only used for the tumor masks postprocessing to split masks into core and periphery regions.","title":"postprocess_masks()"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing.postprocess_masks--parameters","text":"data_path : (pathlib.PosixPath) relative path to the segmented masks. method : (str) function which should be apply in order to postprocess masks. Thus far we only use 'split_tumor_into_core_and_periphery' function. method_parameters : (Dict) parameters to use for the function applied in method argument.","title":"Parameters"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing.postprocess_masks--returns","text":"output_directory (pathlib.PosixPath) : Path where the results have been dumped on the disk to.","title":"Returns"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing.postprocess_masks--example-usuage","text":">>> from src.segmentation import postprocess_masks >>> postprocess_masks ( input_directory = Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/segmentation/tumor/segment___thresholding___method-th_triangle' ), method = 'split_tumor_into_core_and_periphery' , method_parameters = { 'periphery_as_ratio_of_max_distance' : 0.6 } Source code in src/segmentation_postprocessing.py @log_step def postprocess_masks ( data_path : pathlib . PosixPath , method : str , method_parameters : Dict ) -> pathlib . PosixPath : \"\"\" Wrapper function, which handles the masks postprocessing within the pipeline. For now only used for the tumor masks postprocessing to split masks into core and periphery regions. Parameters ---------- **data_path** : *(pathlib.PosixPath)* relative path to the segmented masks. **method**: *(str)* function which should be apply in order to postprocess masks. Thus far we only use 'split_tumor_into_core_and_periphery' function. **method_parameters**: *(Dict)* parameters to use for the function applied in **method** argument. Returns ------ output_directory *(pathlib.PosixPath)*: Path where the results have been dumped on the disk to. Example Usuage -------------- ```python >>>from src.segmentation import postprocess_masks >>>postprocess_masks( input_directory = Path('ppdm/data/5IT_DUMMY_STUDY/results/segmentation/tumor/segment___thresholding___method-th_triangle'), method = 'split_tumor_into_core_and_periphery', method_parameters = {'periphery_as_ratio_of_max_distance': 0.6} ``` \"\"\" module_results_path = \"results/segmentation_postprocessing\" module_name = \"postprocess_masks\" segmentation_postprocessing_function = getattr ( sys . modules [ __name__ ], method ) parameters_as_string = join_keys_and_values_to_list ( method_parameters ) output_folder_name = join_to_string ( [ module_name , method , * parameters_as_string , data_path . stem ] ) output_directory = create_relative_path ( data_path , module_results_path , output_folder_name , _infer_root_based_on = \"results\" , ) directory_ok = check_content_of_two_directories ( data_path , output_directory ) if directory_ok is False : if output_directory . exists (): remove_content ( output_directory ) segmentation_postprocessing_function ( data_path , output_directory , ** method_parameters ) return output_directory","title":"Example Usuage"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing.split_tumor_into_core_and_periphery","text":"Function which splits tumor into core and periphery based on relative distance from the surface.","title":"split_tumor_into_core_and_periphery()"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing.split_tumor_into_core_and_periphery--parameters","text":"input_directory : (pathlib.PosixPath) relative path to the segmented masks. output_directory : (pathlib.PosixPath) relative path where the results should be saved to. periphery_as_ratio_of_max_distance : (float) what ratio of the tumor should be consired core. Any number in <0;1>","title":"Parameters"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing.split_tumor_into_core_and_periphery--returns","text":"None: Results are dumped on the disk.","title":"Returns"},{"location":"Modules/segmentation_postprocessing/#src.segmentation_postprocessing.split_tumor_into_core_and_periphery--example-usuage","text":">>> from src.segmentation import split_tumor_into_core_and_periphery >>> split_tumor_into_core_and_periphery ( input_directory = Path ( 'ppdm/data/5IT_DUMMY_STUDY/results/segmentation/tumor/segment___thresholding___method-th_triangle' ), output_directory = Path ( 'ppdm/data/my_tumor_folder' ), periphery_as_ratio_of_max_distance = 0.5 ) Source code in src/segmentation_postprocessing.py def split_tumor_into_core_and_periphery ( input_directory : pathlib . PosixPath , output_directory : pathlib . PosixPath , periphery_as_ratio_of_max_distance : float = 0.2 , ) -> None : \"\"\" Function which splits tumor into core and periphery based on relative distance from the surface. Parameters ---------- **input_directory** : *(pathlib.PosixPath)* relative path to the segmented masks. **output_directory** : *(pathlib.PosixPath)* relative path where the results should be saved to. **periphery_as_ratio_of_max_distance**: *(float)* what ratio of the tumor should be consired core. Any number in <0;1> Returns ------ None: Results are dumped on the disk. Example Usuage -------------- ```python >>>from src.segmentation import split_tumor_into_core_and_periphery >>>split_tumor_into_core_and_periphery( input_directory = Path('ppdm/data/5IT_DUMMY_STUDY/results/segmentation/tumor/segment___thresholding___method-th_triangle'), output_directory = Path('ppdm/data/my_tumor_folder'), periphery_as_ratio_of_max_distance = 0.5) ``` \"\"\" original_images = sorted ( list ( input_directory . glob ( \"*.npy\" ))) imgs_tumor_mask_list = parallel ( _load_and_transform_image , original_images , n_workers = 12 , threadpool = True , progress = True , ) # check if layers (baesed on image names) are ordered correctly layer_names = [ x [ \"name\" ] for x in imgs_tumor_mask_list ] imgs_tum = _stack_and_downscale_images ( imgs_tumor_mask_list ) # do distance transform imgs_tum_dt = edt . edt ( imgs_tum , black_border = False , parallel = 12 , order = \"C\" ) # split masked object into core and periphery based on distance from surface distance_threshold = periphery_as_ratio_of_max_distance * np . max ( imgs_tum_dt ) imgs_outer = np . where ( imgs_tum_dt < distance_threshold , imgs_tum_dt , 0 ,) # inner mask # make sure inner mask is binary outer_mask = np . where ( imgs_outer > 0 , 1 , 0 ) # outer mask inner_mask = imgs_tum - outer_mask # resize z-axis back to original inner_mask = zoom ( inner_mask , ( 10 , 1 , 1 ), mode = \"nearest\" , order = 0 ) outer_mask = zoom ( outer_mask , ( 10 , 1 , 1 ), mode = \"nearest\" , order = 0 ) # save to disk mask_path = output_directory mask_path . parent . mkdir ( exist_ok = True , parents = True ) inner_mask_iterable = [ x for x in inner_mask ] outer_mask_iterable = [ x for x in outer_mask ] inner_outer_mask_individual_layers = [ { \"name\" : layer_name , \"image_path\" : layer_image , \"core_periphery\" : core_periphery , } for layer_name , layer_image , core_periphery in zip ( layer_names , original_images , zip ( inner_mask_iterable , outer_mask_iterable ), ) ] parallel ( partial ( _encode_combine_transform_and_save_mask , output_directory = mask_path ), inner_outer_mask_individual_layers , n_workers = 12 , progress = True , threadpool = True , )","title":"Example Usuage"},{"location":"Overview/intro/","text":"This is a intor file for i in range ( 20 ): print ( i )","title":"This is a intor file"},{"location":"Overview/intro/#this-is-a-intor-file","text":"for i in range ( 20 ): print ( i )","title":"This is a intor file"}]}